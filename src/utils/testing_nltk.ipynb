{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/41039801/nltk-kneserneyprobdist-is-giving-0-25-probability-distribution-for-most-of-the-t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smoothing and interpolation:\n",
    "   -  http://www.cs.columbia.edu/~mcollins/lm-spring2013.pdf\n",
    "   -  https://www.statmt.org/book/slides/07-language-models.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "import nltk\n",
    "# from nltk.util import ngrams\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# from preprocessor import utf8_to_ascii\n",
    "\n",
    "# with io.open(\"mypet.txt\",'r',encoding='utf8') as utf_file:\n",
    "#     file_content = utf_file.read()\n",
    "\n",
    "# ascii_content = utf8_to_ascii(file_content)\n",
    "# sentence_tokenize_list = sent_tokenize(ascii_content)\n",
    "\n",
    "# all_tgrams = []\n",
    "# for sentence in sentence_tokenize_list:\n",
    "#     sentence = sentence.rstrip('.!?')\n",
    "#     tokens = nltk.re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", sentence)\n",
    "#     tgrams = ngrams(tokens, 3,pad_left=True,pad_right=True,left_pad_symbol='<s>', right_pad_symbol=\"</s>\")\n",
    "#     all_tgrams.extend(tgrams)\n",
    "\n",
    "# frequency_distribution = nltk.FreqDist(all_tgrams)\n",
    "# kneser_ney = nltk.KneserNeyProbDist(frequency_distribution)\n",
    "# for i in kneser_ney.samples():\n",
    "#     print \"{0}: {1}\".format(kneser_ney.prob(i), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from article import Library\n",
    "path = '/Users/stzeng/code/github/autograder/data/newsela_article_corpus_2016-01-29/'\n",
    "library = Library(path)\n",
    "library.create_grade_level_library()\n",
    "# print(library.library['zuckerberg-internet'].article_text(4.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>version</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1730</td>\n",
       "      <td>1730</td>\n",
       "      <td>1730</td>\n",
       "      <td>1730</td>\n",
       "      <td>1730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1488</td>\n",
       "      <td>1488</td>\n",
       "      <td>1488</td>\n",
       "      <td>1488</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1171</td>\n",
       "      <td>1171</td>\n",
       "      <td>1171</td>\n",
       "      <td>1171</td>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1365</td>\n",
       "      <td>1365</td>\n",
       "      <td>1365</td>\n",
       "      <td>1365</td>\n",
       "      <td>1365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1152</td>\n",
       "      <td>1152</td>\n",
       "      <td>1152</td>\n",
       "      <td>1152</td>\n",
       "      <td>1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2096</td>\n",
       "      <td>2096</td>\n",
       "      <td>2096</td>\n",
       "      <td>2096</td>\n",
       "      <td>2096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             slug  language  title  version  filename\n",
       "grade_level                                          \n",
       "2             283       283    283      283       283\n",
       "3             616       616    616      616       616\n",
       "4            1730      1730   1730     1730      1730\n",
       "5            1488      1488   1488     1488      1488\n",
       "6            1171      1171   1171     1171      1171\n",
       "7            1365      1365   1365     1365      1365\n",
       "8            1152      1152   1152     1152      1152\n",
       "9             862       862    862      862       862\n",
       "10             21        21     21       21        21\n",
       "11              2         2      2        2         2\n",
       "12           2096      2096   2096     2096      2096"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library.metadata.groupby('grade_level').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library.grade_level_vocabulary(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(ngrams(library.grade_level_tokenized_sentences.get(10), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'WASHINGTON', 'It'),\n",
       " ('WASHINGTON', 'It', 'is'),\n",
       " ('It', 'is', 'time'),\n",
       " ('is', 'time', 'that'),\n",
       " ('time', 'that', 'a'),\n",
       " ('that', 'a', 'woman'),\n",
       " ('a', 'woman', 'be'),\n",
       " ('woman', 'be', 'on'),\n",
       " ('be', 'on', 'American'),\n",
       " ('on', 'American', 'money'),\n",
       " ('American', 'money', 'the'),\n",
       " ('money', 'the', 'head'),\n",
       " ('the', 'head', 'of'),\n",
       " ('head', 'of', 'the'),\n",
       " ('of', 'the', 'U'),\n",
       " ('the', 'U', '.'),\n",
       " ('U', '.', 'S'),\n",
       " ('.', 'S', '.'),\n",
       " ('S', '.', 'Treasury'),\n",
       " ('.', 'Treasury', 'Department'),\n",
       " ('Treasury', 'Department', 'said'),\n",
       " ('Department', 'said', '</s>'),\n",
       " ('said', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'We'),\n",
       " ('<s>', 'We', 'will'),\n",
       " ('We', 'will', 'right'),\n",
       " ('will', 'right', 'that'),\n",
       " ('right', 'that', 'wrong'),\n",
       " ('that', 'wrong', 'Treasury'),\n",
       " ('wrong', 'Treasury', 'Secretary'),\n",
       " ('Treasury', 'Secretary', 'Jacob'),\n",
       " ('Secretary', 'Jacob', 'J'),\n",
       " ('Jacob', 'J', '.'),\n",
       " ('J', '.', 'Lew'),\n",
       " ('.', 'Lew', 'promised'),\n",
       " ('Lew', 'promised', '</s>'),\n",
       " ('promised', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'new'),\n",
       " ('The', 'new', '10'),\n",
       " ('new', '10', 'bill'),\n",
       " ('10', 'bill', 'will'),\n",
       " ('bill', 'will', 'include'),\n",
       " ('will', 'include', 'the'),\n",
       " ('include', 'the', 'picture'),\n",
       " ('the', 'picture', 'of'),\n",
       " ('picture', 'of', 'a'),\n",
       " ('of', 'a', 'woman'),\n",
       " ('a', 'woman', '</s>'),\n",
       " ('woman', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Who'),\n",
       " ('<s>', 'Who', 'are'),\n",
       " ('Who', 'are', 'some'),\n",
       " ('are', 'some', 'of'),\n",
       " ('some', 'of', 'the'),\n",
       " ('of', 'the', 'candidates'),\n",
       " ('the', 'candidates', 'to'),\n",
       " ('candidates', 'to', 'be'),\n",
       " ('to', 'be', 'the'),\n",
       " ('be', 'the', 'first'),\n",
       " ('the', 'first', 'woman'),\n",
       " ('first', 'woman', 'on'),\n",
       " ('woman', 'on', 'American'),\n",
       " ('on', 'American', 'paper'),\n",
       " ('American', 'paper', 'money'),\n",
       " ('paper', 'money', 'in'),\n",
       " ('money', 'in', 'more'),\n",
       " ('in', 'more', 'than'),\n",
       " ('more', 'than', 'a'),\n",
       " ('than', 'a', 'century'),\n",
       " ('a', 'century', '</s>'),\n",
       " ('century', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'A'),\n",
       " ('<s>', 'A', 'former'),\n",
       " ('A', 'former', 'slave'),\n",
       " ('former', 'slave', 'who'),\n",
       " ('slave', 'who', 'helped'),\n",
       " ('who', 'helped', 'to'),\n",
       " ('helped', 'to', 'end'),\n",
       " ('to', 'end', 'slavery'),\n",
       " ('end', 'slavery', '</s>'),\n",
       " ('slavery', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'longest-serving'),\n",
       " ('The', 'longest-serving', 'first'),\n",
       " ('longest-serving', 'first', 'lady'),\n",
       " ('first', 'lady', '</s>'),\n",
       " ('lady', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'A'),\n",
       " ('<s>', 'A', 'top'),\n",
       " ('A', 'top', 'government'),\n",
       " ('top', 'government', 'worker'),\n",
       " ('government', 'worker', '</s>'),\n",
       " ('worker', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'woman'),\n",
       " ('The', 'woman', 'who'),\n",
       " ('woman', 'who', 'started'),\n",
       " ('who', 'started', 'the'),\n",
       " ('started', 'the', 'Girl'),\n",
       " ('the', 'Girl', 'Scouts'),\n",
       " ('Girl', 'Scouts', '</s>'),\n",
       " ('Scouts', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Lew'),\n",
       " ('<s>', 'Lew', 'has'),\n",
       " ('Lew', 'has', 'the'),\n",
       " ('has', 'the', 'final'),\n",
       " ('the', 'final', 'decision'),\n",
       " ('final', 'decision', 'but'),\n",
       " ('decision', 'but', 'in'),\n",
       " ('but', 'in', 'the'),\n",
       " ('in', 'the', 'meantime'),\n",
       " ('the', 'meantime', 'he'),\n",
       " ('meantime', 'he', 'and'),\n",
       " ('he', 'and', 'other'),\n",
       " ('and', 'other', 'Treasury'),\n",
       " ('other', 'Treasury', 'people'),\n",
       " ('Treasury', 'people', 'will'),\n",
       " ('people', 'will', 'go'),\n",
       " ('will', 'go', 'across'),\n",
       " ('go', 'across', 'the'),\n",
       " ('across', 'the', 'country'),\n",
       " ('the', 'country', 'to'),\n",
       " ('country', 'to', 'ask'),\n",
       " ('to', 'ask', 'for'),\n",
       " ('ask', 'for', 'suggestions'),\n",
       " ('for', 'suggestions', '</s>'),\n",
       " ('suggestions', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'Treasury'),\n",
       " ('The', 'Treasury', 'prints'),\n",
       " ('Treasury', 'prints', 'money'),\n",
       " ('prints', 'money', 'for'),\n",
       " ('money', 'for', 'the'),\n",
       " ('for', 'the', 'American'),\n",
       " ('the', 'American', 'government'),\n",
       " ('American', 'government', '</s>'),\n",
       " ('government', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'It'),\n",
       " ('<s>', 'It', 'is'),\n",
       " ('It', 'is', 'collecting'),\n",
       " ('is', 'collecting', 'suggestions'),\n",
       " ('collecting', 'suggestions', 'on'),\n",
       " ('suggestions', 'on', 'the'),\n",
       " ('on', 'the', 'website'),\n",
       " ('the', 'website', 'thenew10'),\n",
       " ('website', 'thenew10', '.'),\n",
       " ('thenew10', '.', 'treasury'),\n",
       " ('.', 'treasury', '.'),\n",
       " ('treasury', '.', 'gov'),\n",
       " ('.', 'gov', 'and'),\n",
       " ('gov', 'and', 'on'),\n",
       " ('and', 'on', 'the'),\n",
       " ('on', 'the', 'Twitter'),\n",
       " ('the', 'Twitter', 'hashtag'),\n",
       " ('Twitter', 'hashtag', 'TheNew10'),\n",
       " ('hashtag', 'TheNew10', '.'),\n",
       " ('TheNew10', '.', '</s>'),\n",
       " ('.', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Tubman'),\n",
       " ('<s>', 'Tubman', 'Roosevelt'),\n",
       " ('Tubman', 'Roosevelt', 'Lead'),\n",
       " ('Roosevelt', 'Lead', 'The'),\n",
       " ('Lead', 'The', 'Pack'),\n",
       " ('The', 'Pack', 'A'),\n",
       " ('Pack', 'A', 'group'),\n",
       " ('A', 'group', 'called'),\n",
       " ('group', 'called', 'Women'),\n",
       " ('called', 'Women', 'On'),\n",
       " ('Women', 'On', '20s'),\n",
       " ('On', '20s', 'was'),\n",
       " ('20s', 'was', 'trying'),\n",
       " ('was', 'trying', 'to'),\n",
       " ('trying', 'to', 'get'),\n",
       " ('to', 'get', 'a'),\n",
       " ('get', 'a', \"woman's\"),\n",
       " ('a', \"woman's\", 'image'),\n",
       " (\"woman's\", 'image', 'on'),\n",
       " ('image', 'on', 'the'),\n",
       " ('on', 'the', '20'),\n",
       " ('the', '20', 'bill'),\n",
       " ('20', 'bill', '</s>'),\n",
       " ('bill', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'group'),\n",
       " ('The', 'group', 'took'),\n",
       " ('group', 'took', 'an'),\n",
       " ('took', 'an', 'opinion'),\n",
       " ('an', 'opinion', 'survey'),\n",
       " ('opinion', 'survey', 'and'),\n",
       " ('survey', 'and', 'the'),\n",
       " ('and', 'the', 'winner'),\n",
       " ('the', 'winner', 'was'),\n",
       " ('winner', 'was', 'Harriet'),\n",
       " ('was', 'Harriet', 'Tubman'),\n",
       " ('Harriet', 'Tubman', '</s>'),\n",
       " ('Tubman', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'She'),\n",
       " ('<s>', 'She', 'was'),\n",
       " ('She', 'was', 'a'),\n",
       " ('was', 'a', 'black'),\n",
       " ('a', 'black', 'woman'),\n",
       " ('black', 'woman', 'who'),\n",
       " ('woman', 'who', 'was'),\n",
       " ('who', 'was', 'an'),\n",
       " ('was', 'an', 'escaped'),\n",
       " ('an', 'escaped', 'slave'),\n",
       " ('escaped', 'slave', '</s>'),\n",
       " ('slave', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Tubman'),\n",
       " ('<s>', 'Tubman', 'became'),\n",
       " ('Tubman', 'became', 'one'),\n",
       " ('became', 'one', 'of'),\n",
       " ('one', 'of', 'the'),\n",
       " ('of', 'the', \"country's\"),\n",
       " ('the', \"country's\", 'leading'),\n",
       " (\"country's\", 'leading', 'abolitionists'),\n",
       " ('leading', 'abolitionists', 'fighting'),\n",
       " ('abolitionists', 'fighting', 'to'),\n",
       " ('fighting', 'to', 'free'),\n",
       " ('to', 'free', 'slaves'),\n",
       " ('free', 'slaves', 'before'),\n",
       " ('slaves', 'before', 'the'),\n",
       " ('before', 'the', 'Civil'),\n",
       " ('the', 'Civil', 'War'),\n",
       " ('Civil', 'War', '</s>'),\n",
       " ('War', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Tubman'),\n",
       " ('<s>', 'Tubman', 'helped'),\n",
       " ('Tubman', 'helped', 'hundreds'),\n",
       " ('helped', 'hundreds', 'of'),\n",
       " ('hundreds', 'of', 'slaves'),\n",
       " ('of', 'slaves', 'reach'),\n",
       " ('slaves', 'reach', 'freedom'),\n",
       " ('reach', 'freedom', 'in'),\n",
       " ('freedom', 'in', 'the'),\n",
       " ('in', 'the', 'North'),\n",
       " ('the', 'North', '</s>'),\n",
       " ('North', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'She'),\n",
       " ('<s>', 'She', 'got'),\n",
       " ('She', 'got', '118'),\n",
       " ('got', '118', '328'),\n",
       " ('118', '328', 'out'),\n",
       " ('328', 'out', 'of'),\n",
       " ('out', 'of', '352'),\n",
       " ('of', '352', '431'),\n",
       " ('352', '431', 'total'),\n",
       " ('431', 'total', 'votes'),\n",
       " ('total', 'votes', '</s>'),\n",
       " ('votes', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'Treasury'),\n",
       " ('The', 'Treasury', 'Department'),\n",
       " ('Treasury', 'Department', 'will'),\n",
       " ('Department', 'will', 'hold'),\n",
       " ('will', 'hold', 'public'),\n",
       " ('hold', 'public', 'meetings'),\n",
       " ('public', 'meetings', 'starting'),\n",
       " ('meetings', 'starting', 'June'),\n",
       " ('starting', 'June', '24'),\n",
       " ('June', '24', '</s>'),\n",
       " ('24', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'They'),\n",
       " ('<s>', 'They', 'will'),\n",
       " ('They', 'will', 'take'),\n",
       " ('will', 'take', 'place'),\n",
       " ('take', 'place', 'in'),\n",
       " ('place', 'in', 'Texas'),\n",
       " ('in', 'Texas', '</s>'),\n",
       " ('Texas', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Lew'),\n",
       " ('<s>', 'Lew', 'will'),\n",
       " ('Lew', 'will', 'attend'),\n",
       " ('will', 'attend', 'some'),\n",
       " ('attend', 'some', 'of'),\n",
       " ('some', 'of', 'those'),\n",
       " ('of', 'those', 'meetings'),\n",
       " ('those', 'meetings', '</s>'),\n",
       " ('meetings', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'He'),\n",
       " ('<s>', 'He', 'said'),\n",
       " ('He', 'said', 'he'),\n",
       " ('said', 'he', 'has'),\n",
       " ('he', 'has', 'a'),\n",
       " ('has', 'a', 'bunch'),\n",
       " ('a', 'bunch', 'of'),\n",
       " ('bunch', 'of', 'candidates'),\n",
       " ('of', 'candidates', 'but'),\n",
       " ('candidates', 'but', 'plans'),\n",
       " ('but', 'plans', 'to'),\n",
       " ('plans', 'to', 'wait'),\n",
       " ('to', 'wait', 'until'),\n",
       " ('wait', 'until', 'he'),\n",
       " ('until', 'he', 'hears'),\n",
       " ('he', 'hears', 'from'),\n",
       " ('hears', 'from', 'the'),\n",
       " ('from', 'the', 'American'),\n",
       " ('the', 'American', 'people'),\n",
       " ('American', 'people', '</s>'),\n",
       " ('people', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'He'),\n",
       " ('<s>', 'He', 'will'),\n",
       " ('He', 'will', 'make'),\n",
       " ('will', 'make', 'a'),\n",
       " ('make', 'a', 'decision'),\n",
       " ('a', 'decision', 'later'),\n",
       " ('decision', 'later', 'this'),\n",
       " ('later', 'this', 'year'),\n",
       " ('this', 'year', '</s>'),\n",
       " ('year', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'To'),\n",
       " ('<s>', 'To', 'be'),\n",
       " ('To', 'be', 'considered'),\n",
       " ('be', 'considered', 'the'),\n",
       " ('considered', 'the', 'woman'),\n",
       " ('the', 'woman', 'must'),\n",
       " ('woman', 'must', 'be'),\n",
       " ('must', 'be', 'dead'),\n",
       " ('be', 'dead', 'and'),\n",
       " ('dead', 'and', 'have'),\n",
       " ('and', 'have', 'helped'),\n",
       " ('have', 'helped', 'democracy'),\n",
       " ('helped', 'democracy', 'which'),\n",
       " ('democracy', 'which', 'is'),\n",
       " ('which', 'is', 'the'),\n",
       " ('is', 'the', 'theme'),\n",
       " ('the', 'theme', '</s>'),\n",
       " ('theme', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Eleanor'),\n",
       " ('<s>', 'Eleanor', 'Roosevelt'),\n",
       " ('Eleanor', 'Roosevelt', 'was'),\n",
       " ('Roosevelt', 'was', 'the'),\n",
       " ('was', 'the', 'wife'),\n",
       " ('the', 'wife', 'of'),\n",
       " ('wife', 'of', 'President'),\n",
       " ('of', 'President', 'Franklin'),\n",
       " ('President', 'Franklin', 'D'),\n",
       " ('Franklin', 'D', '.'),\n",
       " ('D', '.', 'Roosevelt'),\n",
       " ('.', 'Roosevelt', '</s>'),\n",
       " ('Roosevelt', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'She'),\n",
       " ('<s>', 'She', 'was'),\n",
       " ('She', 'was', 'first'),\n",
       " ('was', 'first', 'lady'),\n",
       " ('first', 'lady', 'from'),\n",
       " ('lady', 'from', '1933'),\n",
       " ('from', '1933', 'to'),\n",
       " ('1933', 'to', '1945'),\n",
       " ('to', '1945', 'and'),\n",
       " ('1945', 'and', 'fought'),\n",
       " ('and', 'fought', 'for'),\n",
       " ('fought', 'for', \"women's\"),\n",
       " ('for', \"women's\", 'rights'),\n",
       " (\"women's\", 'rights', 'and'),\n",
       " ('rights', 'and', 'civil'),\n",
       " ('and', 'civil', 'rights'),\n",
       " ('civil', 'rights', '</s>'),\n",
       " ('rights', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Roosevelt'),\n",
       " ('<s>', 'Roosevelt', 'came'),\n",
       " ('Roosevelt', 'came', 'in'),\n",
       " ('came', 'in', 'second'),\n",
       " ('in', 'second', 'in'),\n",
       " ('second', 'in', 'the'),\n",
       " ('in', 'the', 'Women'),\n",
       " ('the', 'Women', 'On'),\n",
       " ('Women', 'On', '20s'),\n",
       " ('On', '20s', 'survey'),\n",
       " ('20s', 'survey', '</s>'),\n",
       " ('survey', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'Girl'),\n",
       " ('The', 'Girl', 'Scouts'),\n",
       " ('Girl', 'Scouts', 'supports'),\n",
       " ('Scouts', 'supports', 'Juliette'),\n",
       " ('supports', 'Juliette', 'Gordon'),\n",
       " ('Juliette', 'Gordon', 'Low'),\n",
       " ('Gordon', 'Low', 'who'),\n",
       " ('Low', 'who', 'started'),\n",
       " ('who', 'started', 'the'),\n",
       " ('started', 'the', 'organization'),\n",
       " ('the', 'organization', 'in'),\n",
       " ('organization', 'in', '1912'),\n",
       " ('in', '1912', '</s>'),\n",
       " ('1912', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'She'),\n",
       " ('<s>', 'She', 'was'),\n",
       " ('She', 'was', 'a'),\n",
       " ('was', 'a', 'champion'),\n",
       " ('a', 'champion', 'for'),\n",
       " ('champion', 'for', 'democracy'),\n",
       " ('for', 'democracy', 'and'),\n",
       " ('democracy', 'and', 'a'),\n",
       " ('and', 'a', 'force'),\n",
       " ('a', 'force', 'for'),\n",
       " ('force', 'for', 'good'),\n",
       " ('for', 'good', 'the'),\n",
       " ('good', 'the', 'Girl'),\n",
       " ('the', 'Girl', 'Scouts'),\n",
       " ('Girl', 'Scouts', 'said'),\n",
       " ('Scouts', 'said', 'on'),\n",
       " ('said', 'on', 'Twitter'),\n",
       " ('on', 'Twitter', '</s>'),\n",
       " ('Twitter', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'New'),\n",
       " ('<s>', 'New', '10'),\n",
       " ('New', '10', 'Bill'),\n",
       " ('10', 'Bill', 'Will'),\n",
       " ('Bill', 'Will', 'Celebrate'),\n",
       " ('Will', 'Celebrate', '19th'),\n",
       " ('Celebrate', '19th', 'Amendment'),\n",
       " ('19th', 'Amendment', 'The'),\n",
       " ('Amendment', 'The', 'Treasury'),\n",
       " ('The', 'Treasury', 'Department'),\n",
       " ('Treasury', 'Department', 'expects'),\n",
       " ('Department', 'expects', 'to'),\n",
       " ('expects', 'to', 'present'),\n",
       " ('to', 'present', 'the'),\n",
       " ('present', 'the', 'new'),\n",
       " ('the', 'new', '10'),\n",
       " ('new', '10', 'bill'),\n",
       " ('10', 'bill', 'in'),\n",
       " ('bill', 'in', '2020'),\n",
       " ('in', '2020', '</s>'),\n",
       " ('2020', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'year'),\n",
       " ('The', 'year', 'will'),\n",
       " ('year', 'will', 'mark'),\n",
       " ('will', 'mark', 'the'),\n",
       " ('mark', 'the', '100th'),\n",
       " ('the', '100th', 'anniversary'),\n",
       " ('100th', 'anniversary', 'of'),\n",
       " ('anniversary', 'of', 'the'),\n",
       " ('of', 'the', '19th'),\n",
       " ('the', '19th', 'Amendment'),\n",
       " ('19th', 'Amendment', 'to'),\n",
       " ('Amendment', 'to', 'the'),\n",
       " ('to', 'the', 'U'),\n",
       " ('the', 'U', '.'),\n",
       " ('U', '.', 'S'),\n",
       " ('.', 'S', '.'),\n",
       " ('S', '.', 'Constitution'),\n",
       " ('.', 'Constitution', 'which'),\n",
       " ('Constitution', 'which', 'gave'),\n",
       " ('which', 'gave', 'women'),\n",
       " ('gave', 'women', 'the'),\n",
       " ('women', 'the', 'right'),\n",
       " ('the', 'right', 'to'),\n",
       " ('right', 'to', 'vote'),\n",
       " ('to', 'vote', '</s>'),\n",
       " ('vote', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'It'),\n",
       " ('<s>', 'It', 'may'),\n",
       " ('It', 'may', 'take'),\n",
       " ('may', 'take', 'a'),\n",
       " ('take', 'a', 'long'),\n",
       " ('a', 'long', 'time'),\n",
       " ('long', 'time', 'until'),\n",
       " ('time', 'until', 'people'),\n",
       " ('until', 'people', 'are'),\n",
       " ('people', 'are', 'actually'),\n",
       " ('are', 'actually', 'able'),\n",
       " ('actually', 'able', 'to'),\n",
       " ('able', 'to', 'use'),\n",
       " ('to', 'use', 'the'),\n",
       " ('use', 'the', 'new'),\n",
       " ('the', 'new', 'money'),\n",
       " ('new', 'money', '</s>'),\n",
       " ('money', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', '100'),\n",
       " ('The', '100', 'bill'),\n",
       " ('100', 'bill', 'that'),\n",
       " ('bill', 'that', 'came'),\n",
       " ('that', 'came', 'out'),\n",
       " ('came', 'out', '2013'),\n",
       " ('out', '2013', 'took'),\n",
       " ('2013', 'took', 'about'),\n",
       " ('took', 'about', '14'),\n",
       " ('about', '14', 'years'),\n",
       " ('14', 'years', '</s>'),\n",
       " ('years', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Barbara'),\n",
       " ('<s>', 'Barbara', 'Ortiz'),\n",
       " ('Barbara', 'Ortiz', 'Howard'),\n",
       " ('Ortiz', 'Howard', 'started'),\n",
       " ('Howard', 'started', 'Women'),\n",
       " ('started', 'Women', 'On'),\n",
       " ('Women', 'On', '20s'),\n",
       " ('On', '20s', '</s>'),\n",
       " ('20s', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'She'),\n",
       " ('<s>', 'She', 'said'),\n",
       " ('She', 'said', 'the'),\n",
       " ('said', 'the', 'group'),\n",
       " ('the', 'group', 'is'),\n",
       " ('group', 'is', 'fine'),\n",
       " ('is', 'fine', 'with'),\n",
       " ('fine', 'with', 'a'),\n",
       " ('with', 'a', 'woman'),\n",
       " ('a', 'woman', 'on'),\n",
       " ('woman', 'on', '10'),\n",
       " ('on', '10', 'rather'),\n",
       " ('10', 'rather', 'than'),\n",
       " ('rather', 'than', '20'),\n",
       " ('than', '20', 'bills'),\n",
       " ('20', 'bills', '</s>'),\n",
       " ('bills', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'important'),\n",
       " ('The', 'important', 'thing'),\n",
       " ('important', 'thing', 'is'),\n",
       " ('thing', 'is', 'that'),\n",
       " ('is', 'that', 'a'),\n",
       " ('that', 'a', 'female'),\n",
       " ('a', 'female', 'will'),\n",
       " ('female', 'will', 'be'),\n",
       " ('will', 'be', 'on'),\n",
       " ('be', 'on', 'money'),\n",
       " ('on', 'money', 'by'),\n",
       " ('money', 'by', 'the'),\n",
       " ('by', 'the', '100th'),\n",
       " ('the', '100th', 'anniversary'),\n",
       " ('100th', 'anniversary', 'of'),\n",
       " ('anniversary', 'of', 'the'),\n",
       " ('of', 'the', 'voting'),\n",
       " ('the', 'voting', 'rights'),\n",
       " ('voting', 'rights', 'amendment'),\n",
       " ('rights', 'amendment', 'Howard'),\n",
       " ('amendment', 'Howard', 'said'),\n",
       " ('Howard', 'said', '</s>'),\n",
       " ('said', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Another'),\n",
       " ('<s>', 'Another', 'candidate'),\n",
       " ('Another', 'candidate', 'could'),\n",
       " ('candidate', 'could', 'be'),\n",
       " ('could', 'be', 'Frances'),\n",
       " ('be', 'Frances', 'Perkins'),\n",
       " ('Frances', 'Perkins', '</s>'),\n",
       " ('Perkins', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'She'),\n",
       " ('<s>', 'She', 'was'),\n",
       " ('She', 'was', 'the'),\n",
       " ('was', 'the', \"government's\"),\n",
       " ('the', \"government's\", 'Labor'),\n",
       " (\"government's\", 'Labor', 'secretary'),\n",
       " ('Labor', 'secretary', 'from'),\n",
       " ('secretary', 'from', '1933'),\n",
       " ('from', '1933', 'to'),\n",
       " ('1933', 'to', '1945'),\n",
       " ('to', '1945', 'and'),\n",
       " ('1945', 'and', 'the'),\n",
       " ('and', 'the', 'first'),\n",
       " ('the', 'first', 'top'),\n",
       " ('first', 'top', 'woman'),\n",
       " ('top', 'woman', 'official'),\n",
       " ('woman', 'official', 'to'),\n",
       " ('official', 'to', 'advise'),\n",
       " ('to', 'advise', 'the'),\n",
       " ('advise', 'the', 'president'),\n",
       " ('the', 'president', '</s>'),\n",
       " ('president', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Perkins'),\n",
       " ('<s>', 'Perkins', 'helped'),\n",
       " ('Perkins', 'helped', 'begin'),\n",
       " ('helped', 'begin', 'the'),\n",
       " ('begin', 'the', 'minimum'),\n",
       " ('the', 'minimum', 'wage'),\n",
       " ('minimum', 'wage', 'and'),\n",
       " ('wage', 'and', 'the'),\n",
       " ('and', 'the', '40-hour'),\n",
       " ('the', '40-hour', 'work'),\n",
       " ('40-hour', 'work', 'week'),\n",
       " ('work', 'week', '</s>'),\n",
       " ('week', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'minimum'),\n",
       " ('The', 'minimum', 'wage'),\n",
       " ('minimum', 'wage', 'law'),\n",
       " ('wage', 'law', 'says'),\n",
       " ('law', 'says', 'that'),\n",
       " ('says', 'that', 'bosses'),\n",
       " ('that', 'bosses', 'must'),\n",
       " ('bosses', 'must', 'pay'),\n",
       " ('must', 'pay', 'workers'),\n",
       " ('pay', 'workers', 'at'),\n",
       " ('workers', 'at', 'least'),\n",
       " ('at', 'least', 'a'),\n",
       " ('least', 'a', 'certain'),\n",
       " ('a', 'certain', 'amount'),\n",
       " ('certain', 'amount', 'per'),\n",
       " ('amount', 'per', 'hour'),\n",
       " ('per', 'hour', '</s>'),\n",
       " ('hour', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Before'),\n",
       " ('<s>', 'Before', 'that'),\n",
       " ('Before', 'that', 'businesses'),\n",
       " ('that', 'businesses', 'paid'),\n",
       " ('businesses', 'paid', 'workers'),\n",
       " ('paid', 'workers', 'whatever'),\n",
       " ('workers', 'whatever', 'they'),\n",
       " ('whatever', 'they', 'wanted'),\n",
       " ('they', 'wanted', '</s>'),\n",
       " ('wanted', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', '40-hour'),\n",
       " ('The', '40-hour', 'work'),\n",
       " ('40-hour', 'work', 'week'),\n",
       " ('work', 'week', 'made'),\n",
       " ('week', 'made', 'it'),\n",
       " ('made', 'it', 'so'),\n",
       " ('it', 'so', 'that'),\n",
       " ('so', 'that', 'bosses'),\n",
       " ('that', 'bosses', 'could'),\n",
       " ('bosses', 'could', 'not'),\n",
       " ('could', 'not', 'make'),\n",
       " ('not', 'make', 'people'),\n",
       " ('make', 'people', 'work'),\n",
       " ('people', 'work', 'too'),\n",
       " ('work', 'too', 'many'),\n",
       " ('too', 'many', 'hours'),\n",
       " ('many', 'hours', '</s>'),\n",
       " ('hours', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Alexander'),\n",
       " ('<s>', 'Alexander', 'Hamilton'),\n",
       " ('Alexander', 'Hamilton', 'Will'),\n",
       " ('Hamilton', 'Will', 'Still'),\n",
       " ('Will', 'Still', 'Be'),\n",
       " ('Still', 'Be', 'Around'),\n",
       " ('Be', 'Around', 'Lew'),\n",
       " ('Around', 'Lew', 'said'),\n",
       " ('Lew', 'said', 'that'),\n",
       " ('said', 'that', 'the'),\n",
       " ('that', 'the', '10'),\n",
       " ('the', '10', 'bill'),\n",
       " ('10', 'bill', 'will'),\n",
       " ('bill', 'will', 'be'),\n",
       " ('will', 'be', 'the'),\n",
       " ('be', 'the', 'first'),\n",
       " ('the', 'first', 'in'),\n",
       " ('first', 'in', 'a'),\n",
       " ('in', 'a', 'new'),\n",
       " ('a', 'new', 'series'),\n",
       " ('new', 'series', 'of'),\n",
       " ('series', 'of', 'redesigned'),\n",
       " ('of', 'redesigned', 'bills'),\n",
       " ('redesigned', 'bills', '</s>'),\n",
       " ('bills', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'All'),\n",
       " ('<s>', 'All', 'of'),\n",
       " ('All', 'of', 'them'),\n",
       " ('of', 'them', 'will'),\n",
       " ('them', 'will', 'include'),\n",
       " ('will', 'include', 'images'),\n",
       " ('include', 'images', 'on'),\n",
       " ('images', 'on', 'the'),\n",
       " ('on', 'the', 'theme'),\n",
       " ('the', 'theme', 'of'),\n",
       " ('theme', 'of', 'democracy'),\n",
       " ('of', 'democracy', '</s>'),\n",
       " ('democracy', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'last'),\n",
       " ('The', 'last', 'time'),\n",
       " ('last', 'time', 'the'),\n",
       " ('time', 'the', 'government'),\n",
       " ('the', 'government', 'swapped'),\n",
       " ('government', 'swapped', 'pictures'),\n",
       " ('swapped', 'pictures', 'on'),\n",
       " ('pictures', 'on', 'money'),\n",
       " ('on', 'money', 'was'),\n",
       " ('money', 'was', 'between'),\n",
       " ('was', 'between', '1914'),\n",
       " ('between', '1914', 'and'),\n",
       " ('1914', 'and', '1928'),\n",
       " ('and', '1928', 'when'),\n",
       " ('1928', 'when', 'four'),\n",
       " ('when', 'four', 'changes'),\n",
       " ('four', 'changes', 'were'),\n",
       " ('changes', 'were', 'made'),\n",
       " ('were', 'made', '</s>'),\n",
       " ('made', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Alexander'),\n",
       " ('<s>', 'Alexander', 'Hamilton'),\n",
       " ('Alexander', 'Hamilton', 'the'),\n",
       " ('Hamilton', 'the', 'first'),\n",
       " ('the', 'first', 'Treasury'),\n",
       " ('first', 'Treasury', 'secretary'),\n",
       " ('Treasury', 'secretary', 'replaced'),\n",
       " ('secretary', 'replaced', 'President'),\n",
       " ('replaced', 'President', 'Andrew'),\n",
       " ('President', 'Andrew', 'Jackson'),\n",
       " ('Andrew', 'Jackson', 'on'),\n",
       " ('Jackson', 'on', 'the'),\n",
       " ('on', 'the', '10'),\n",
       " ('the', '10', 'bill'),\n",
       " ('10', 'bill', '</s>'),\n",
       " ('bill', '</s>', '<s>'),\n",
       " ('</s>', '<s>', \"Jackson's\"),\n",
       " ('<s>', \"Jackson's\", 'image'),\n",
       " (\"Jackson's\", 'image', 'moved'),\n",
       " ('image', 'moved', 'to'),\n",
       " ('moved', 'to', '20'),\n",
       " ('to', '20', 'replacing'),\n",
       " ('20', 'replacing', 'President'),\n",
       " ('replacing', 'President', 'Grover'),\n",
       " ('President', 'Grover', 'Cleveland'),\n",
       " ('Grover', 'Cleveland', 'who'),\n",
       " ('Cleveland', 'who', 'was'),\n",
       " ('who', 'was', 'put'),\n",
       " ('was', 'put', 'on'),\n",
       " ('put', 'on', 'the'),\n",
       " ('on', 'the', '1'),\n",
       " ('the', '1', '000'),\n",
       " ('1', '000', 'bill'),\n",
       " ('000', 'bill', '</s>'),\n",
       " ('bill', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'President'),\n",
       " ('<s>', 'President', 'William'),\n",
       " ('President', 'William', 'McKinley'),\n",
       " ('William', 'McKinley', 'was'),\n",
       " ('McKinley', 'was', 'put'),\n",
       " ('was', 'put', 'on'),\n",
       " ('put', 'on', 'the'),\n",
       " ('on', 'the', '500'),\n",
       " ('the', '500', 'bill'),\n",
       " ('500', 'bill', '</s>'),\n",
       " ('bill', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Lew'),\n",
       " ('<s>', 'Lew', 'has'),\n",
       " ('Lew', 'has', 'said'),\n",
       " ('has', 'said', 'that'),\n",
       " ('said', 'that', \"Hamilton's\"),\n",
       " ('that', \"Hamilton's\", 'image'),\n",
       " (\"Hamilton's\", 'image', 'will'),\n",
       " ('image', 'will', 'remain'),\n",
       " ('will', 'remain', 'part'),\n",
       " ('remain', 'part', 'of'),\n",
       " ('part', 'of', 'the'),\n",
       " ('of', 'the', 'new'),\n",
       " ('the', 'new', '10'),\n",
       " ('new', '10', 'bill'),\n",
       " ('10', 'bill', '</s>'),\n",
       " ('bill', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'last'),\n",
       " ('The', 'last', 'woman'),\n",
       " ('last', 'woman', 'to'),\n",
       " ('woman', 'to', 'appear'),\n",
       " ('to', 'appear', 'on'),\n",
       " ('appear', 'on', 'American'),\n",
       " ('on', 'American', 'paper'),\n",
       " ('American', 'paper', 'money'),\n",
       " ('paper', 'money', 'was'),\n",
       " ('money', 'was', 'Martha'),\n",
       " ('was', 'Martha', 'Washington'),\n",
       " ('Martha', 'Washington', 'the'),\n",
       " ('Washington', 'the', 'wife'),\n",
       " ('the', 'wife', 'of'),\n",
       " ('wife', 'of', 'President'),\n",
       " ('of', 'President', 'George'),\n",
       " ('President', 'George', 'Washington'),\n",
       " ('George', 'Washington', '</s>'),\n",
       " ('Washington', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Her'),\n",
       " ('<s>', 'Her', 'picture'),\n",
       " ('Her', 'picture', 'appeared'),\n",
       " ('picture', 'appeared', 'on'),\n",
       " ('appeared', 'on', 'a'),\n",
       " ('on', 'a', '1'),\n",
       " ('a', '1', 'bill'),\n",
       " ('1', 'bill', 'in'),\n",
       " ('bill', 'in', 'the'),\n",
       " ('in', 'the', 'late'),\n",
       " ('the', 'late', '19th'),\n",
       " ('late', '19th', 'century'),\n",
       " ('19th', 'century', 'more'),\n",
       " ('century', 'more', 'than'),\n",
       " ('more', 'than', '100'),\n",
       " ('than', '100', 'years'),\n",
       " ('100', 'years', 'ago'),\n",
       " ('years', 'ago', '</s>'),\n",
       " ('ago', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'scientists'),\n",
       " ('The', 'scientists', 'in'),\n",
       " ('scientists', 'in', 'this'),\n",
       " ('in', 'this', 'basement'),\n",
       " ('this', 'basement', 'laboratory'),\n",
       " ('basement', 'laboratory', 'are'),\n",
       " ('laboratory', 'are', 'all'),\n",
       " ('are', 'all', 'looking'),\n",
       " ('all', 'looking', 'at'),\n",
       " ('looking', 'at', 'a'),\n",
       " ('at', 'a', 'smartphone'),\n",
       " ('a', 'smartphone', '</s>'),\n",
       " ('smartphone', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'They'),\n",
       " ('<s>', 'They', \"aren't\"),\n",
       " ('They', \"aren't\", 'on'),\n",
       " (\"aren't\", 'on', 'break'),\n",
       " ('on', 'break', 'this'),\n",
       " ('break', 'this', 'is'),\n",
       " ('this', 'is', 'their'),\n",
       " ('is', 'their', 'work'),\n",
       " ('their', 'work', '</s>'),\n",
       " ('work', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Their'),\n",
       " ('<s>', 'Their', 'computer'),\n",
       " ('Their', 'computer', 'science'),\n",
       " ('computer', 'science', 'professor'),\n",
       " ('science', 'professor', 'is'),\n",
       " ('professor', 'is', 'holding'),\n",
       " ('is', 'holding', 'the'),\n",
       " ('holding', 'the', 'phone'),\n",
       " ('the', 'phone', '</s>'),\n",
       " ('phone', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'He'),\n",
       " ('<s>', 'He', 'is'),\n",
       " ('He', 'is', 'walking'),\n",
       " ('is', 'walking', 'through'),\n",
       " ('walking', 'through', 'the'),\n",
       " ('through', 'the', 'University'),\n",
       " ('the', 'University', 'of'),\n",
       " ('University', 'of', \"Minnesota's\"),\n",
       " ('of', \"Minnesota's\", 'Walter'),\n",
       " (\"Minnesota's\", 'Walter', 'Library'),\n",
       " ('Walter', 'Library', '</s>'),\n",
       " ('Library', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'A'),\n",
       " ('<s>', 'A', '3-D'),\n",
       " ('A', '3-D', 'map'),\n",
       " ('3-D', 'map', 'of'),\n",
       " ('map', 'of', 'a'),\n",
       " ('of', 'a', 'nearby'),\n",
       " ('a', 'nearby', 'hallway'),\n",
       " ('nearby', 'hallway', 'is'),\n",
       " ('hallway', 'is', 'appearing'),\n",
       " ('is', 'appearing', 'on'),\n",
       " ('appearing', 'on', 'the'),\n",
       " ('on', 'the', \"phone's\"),\n",
       " ('the', \"phone's\", 'screen'),\n",
       " (\"phone's\", 'screen', 'as'),\n",
       " ('screen', 'as', 'he'),\n",
       " ('as', 'he', 'walks'),\n",
       " ('he', 'walks', '</s>'),\n",
       " ('walks', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', \"phone's\"),\n",
       " ('The', \"phone's\", 'camera'),\n",
       " (\"phone's\", 'camera', 'and'),\n",
       " ('camera', 'and', 'motion'),\n",
       " ('and', 'motion', 'sensor'),\n",
       " ('motion', 'sensor', 'work'),\n",
       " ('sensor', 'work', 'together'),\n",
       " ('work', 'together', 'to'),\n",
       " ('together', 'to', 'collect'),\n",
       " ('to', 'collect', 'information'),\n",
       " ('collect', 'information', 'that'),\n",
       " ('information', 'that', 'becomes'),\n",
       " ('that', 'becomes', 'a'),\n",
       " ('becomes', 'a', '3-D'),\n",
       " ('a', '3-D', 'image'),\n",
       " ('3-D', 'image', '</s>'),\n",
       " ('image', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Graduate'),\n",
       " ('<s>', 'Graduate', 'students'),\n",
       " ('Graduate', 'students', 'at'),\n",
       " ('students', 'at', 'the'),\n",
       " ('at', 'the', 'University'),\n",
       " ('the', 'University', 'of'),\n",
       " ('University', 'of', 'Minnesota'),\n",
       " ('of', 'Minnesota', 'are'),\n",
       " ('Minnesota', 'are', 'working'),\n",
       " ('are', 'working', 'with'),\n",
       " ('working', 'with', 'Google'),\n",
       " ('with', 'Google', 'Inc'),\n",
       " ('Google', 'Inc', '.'),\n",
       " ('Inc', '.', 'to'),\n",
       " ('.', 'to', 'make'),\n",
       " ('to', 'make', 'smartphones'),\n",
       " ('make', 'smartphones', 'that'),\n",
       " ('smartphones', 'that', 'can'),\n",
       " ('that', 'can', 'create'),\n",
       " ('can', 'create', '3-D'),\n",
       " ('create', '3-D', 'maps'),\n",
       " ('3-D', 'maps', 'anywhere'),\n",
       " ('maps', 'anywhere', '</s>'),\n",
       " ('anywhere', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Google'),\n",
       " ('<s>', 'Google', 'gave'),\n",
       " ('Google', 'gave', 'the'),\n",
       " ('gave', 'the', 'university'),\n",
       " ('the', 'university', '1'),\n",
       " ('university', '1', '.'),\n",
       " ('1', '.', '35'),\n",
       " ('.', '35', 'million'),\n",
       " ('35', 'million', 'to'),\n",
       " ('million', 'to', 'develop'),\n",
       " ('to', 'develop', 'this'),\n",
       " ('develop', 'this', 'technology'),\n",
       " ('this', 'technology', '</s>'),\n",
       " ('technology', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Map'),\n",
       " ('<s>', 'Map', 'Making'),\n",
       " ('Map', 'Making', 'In'),\n",
       " ('Making', 'In', '3-D'),\n",
       " ('In', '3-D', 'Smartphones'),\n",
       " ('3-D', 'Smartphones', 'that'),\n",
       " ('Smartphones', 'that', 'can'),\n",
       " ('that', 'can', 'easily'),\n",
       " ('can', 'easily', 'create'),\n",
       " ('easily', 'create', '3-D'),\n",
       " ('create', '3-D', 'maps'),\n",
       " ('3-D', 'maps', 'would'),\n",
       " ('maps', 'would', 'be'),\n",
       " ('would', 'be', 'a'),\n",
       " ('be', 'a', 'huge'),\n",
       " ('a', 'huge', 'breakthrough'),\n",
       " ('huge', 'breakthrough', '</s>'),\n",
       " ('breakthrough', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'smartphones'),\n",
       " ('The', 'smartphones', 'will'),\n",
       " ('smartphones', 'will', 'soon'),\n",
       " ('will', 'soon', 'be'),\n",
       " ('soon', 'be', 'able'),\n",
       " ('be', 'able', 'to'),\n",
       " ('able', 'to', 'give'),\n",
       " ('to', 'give', 'directions'),\n",
       " ('give', 'directions', 'within'),\n",
       " ('directions', 'within', 'a'),\n",
       " ('within', 'a', 'building'),\n",
       " ('a', 'building', 'computer'),\n",
       " ('building', 'computer', 'science'),\n",
       " ('computer', 'science', 'professor'),\n",
       " ('science', 'professor', 'Stergios'),\n",
       " ('professor', 'Stergios', 'Roumeliotis'),\n",
       " ('Stergios', 'Roumeliotis', 'said'),\n",
       " ('Roumeliotis', 'said', '</s>'),\n",
       " ('said', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'They'),\n",
       " ('<s>', 'They', 'could'),\n",
       " ('They', 'could', 'help'),\n",
       " ('could', 'help', 'you'),\n",
       " ('help', 'you', 'to'),\n",
       " ('you', 'to', 'find'),\n",
       " ('to', 'find', 'your'),\n",
       " ('find', 'your', 'classroom'),\n",
       " ('your', 'classroom', 'in'),\n",
       " ('classroom', 'in', 'a'),\n",
       " ('in', 'a', 'huge'),\n",
       " ('a', 'huge', 'school'),\n",
       " ('huge', 'school', 'or'),\n",
       " ('school', 'or', 'find'),\n",
       " ('or', 'find', 'a'),\n",
       " ('find', 'a', 'coffee'),\n",
       " ('a', 'coffee', 'shop'),\n",
       " ('coffee', 'shop', 'in'),\n",
       " ('shop', 'in', 'an'),\n",
       " ('in', 'an', 'airport'),\n",
       " ('an', 'airport', '</s>'),\n",
       " ('airport', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'There'),\n",
       " ('<s>', 'There', 'are'),\n",
       " ('There', 'are', 'other'),\n",
       " ('are', 'other', 'uses'),\n",
       " ('other', 'uses', 'as'),\n",
       " ('uses', 'as', 'well'),\n",
       " ('as', 'well', '</s>'),\n",
       " ('well', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Homeowners'),\n",
       " ('<s>', 'Homeowners', 'could'),\n",
       " ('Homeowners', 'could', 'create'),\n",
       " ('could', 'create', 'a'),\n",
       " ('create', 'a', 'digital'),\n",
       " ('a', 'digital', 'tour'),\n",
       " ('digital', 'tour', 'of'),\n",
       " ('tour', 'of', 'their'),\n",
       " ('of', 'their', 'houses'),\n",
       " ('their', 'houses', 'when'),\n",
       " ('houses', 'when', 'selling'),\n",
       " ('when', 'selling', 'them'),\n",
       " ('selling', 'them', '</s>'),\n",
       " ('them', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'The'),\n",
       " ('<s>', 'The', 'software'),\n",
       " ('The', 'software', 'could'),\n",
       " ('software', 'could', 'also'),\n",
       " ('could', 'also', 'help'),\n",
       " ('also', 'help', 'blind'),\n",
       " ('help', 'blind', 'people'),\n",
       " ('blind', 'people', 'walk'),\n",
       " ('people', 'walk', 'through'),\n",
       " ('walk', 'through', 'a'),\n",
       " ('through', 'a', 'building'),\n",
       " ('a', 'building', 'or'),\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library.grade_level_ngrams(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([12, 8, 6, 5, 3, 9, 7, 4, 2, 10, 11])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library.grade_level_tokenized_sentences.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>version</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10dollarbill-woman</td>\n",
       "      <td>en</td>\n",
       "      <td>Tubman, Perkins or Roosevelt? Woman on $10 bil...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>10dollarbill-woman.en.0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10dollarbill-woman</td>\n",
       "      <td>en</td>\n",
       "      <td>Americans weigh in to choose the woman who wil...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10dollarbill-woman.en.1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10dollarbill-woman</td>\n",
       "      <td>en</td>\n",
       "      <td>The $10 question: Who will be the new face on ...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10dollarbill-woman.en.2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10dollarbill-woman</td>\n",
       "      <td>en</td>\n",
       "      <td>New $10 bill will have a theme and a woman's p...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10dollarbill-woman.en.3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10dollarbill-woman</td>\n",
       "      <td>en</td>\n",
       "      <td>We will soon have an American woman's face on ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10dollarbill-woman.en.4.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 slug language  \\\n",
       "0  10dollarbill-woman       en   \n",
       "1  10dollarbill-woman       en   \n",
       "2  10dollarbill-woman       en   \n",
       "3  10dollarbill-woman       en   \n",
       "4  10dollarbill-woman       en   \n",
       "\n",
       "                                               title  grade_level  version  \\\n",
       "0  Tubman, Perkins or Roosevelt? Woman on $10 bil...           12        0   \n",
       "1  Americans weigh in to choose the woman who wil...            8        1   \n",
       "2  The $10 question: Who will be the new face on ...            6        2   \n",
       "3  New $10 bill will have a theme and a woman's p...            5        3   \n",
       "4  We will soon have an American woman's face on ...            3        4   \n",
       "\n",
       "                      filename  \n",
       "0  10dollarbill-woman.en.0.txt  \n",
       "1  10dollarbill-woman.en.1.txt  \n",
       "2  10dollarbill-woman.en.2.txt  \n",
       "3  10dollarbill-woman.en.3.txt  \n",
       "4  10dollarbill-woman.en.4.txt  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library.metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([12, 8, 6, 5, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library.all_articles['10dollarbill-woman'].grade_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library.all_articles['10dollarbill-woman'].article_text(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library.all_articles['10dollarbill-woman'].n_grams(8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/stzeng/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize list based off of grade level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokenize_list = sent_tokenize(library.library['zuckerberg-internet'].article_text(4.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91419"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(library.grade_level_tokenized_sentences[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(library.grade_level_tokenized_sentences[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10531"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(library.grade_level_tokenized_sentences[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then you create your collocations finder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import TrigramCollocationFinder, TrigramAssocMeasures\n",
    "tcf = TrigramCollocationFinder.from_words(library.grade_level_tokenized_sentences[5])\n",
    "trigram_measures = TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following would give you the best 10 trigrams according to frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('</s>', '<s>', 'The'),\n",
       " ('</s>', '<s>', 'They'),\n",
       " ('</s>', '<s>', 'He'),\n",
       " ('said', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'It'),\n",
       " ('.', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'But'),\n",
       " ('</s>', '<s>', 'She'),\n",
       " ('</s>', '<s>', 'In'),\n",
       " ('</s>', '<s>', 'A'),\n",
       " ('U', '.', 'S'),\n",
       " ('.', 'S', '.'),\n",
       " ('he', 'said', '</s>'),\n",
       " ('</s>', '<s>', 'This'),\n",
       " ('</s>', '<s>', 'I'),\n",
       " ('</s>', '<s>', 'Some'),\n",
       " ('</s>', '<s>', 'There'),\n",
       " ('</s>', '<s>', \"It's\"),\n",
       " ('</s>', '<s>', 'That'),\n",
       " ('</s>', '<s>', 'We'),\n",
       " ('</s>', '<s>', 'And'),\n",
       " ('<s>', 'It', 'is'),\n",
       " ('the', 'United', 'States'),\n",
       " ('</s>', '<s>', 'Many'),\n",
       " ('the', 'U', '.'),\n",
       " ('<s>', 'He', 'said'),\n",
       " ('years', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'For'),\n",
       " ('</s>', '<s>', 'If'),\n",
       " ('it', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Now'),\n",
       " ('</s>', '<s>', 'When'),\n",
       " ('she', 'said', '</s>'),\n",
       " ('</s>', '<s>', 'El'),\n",
       " ('them', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'People'),\n",
       " ('year', '</s>', '<s>'),\n",
       " ('<s>', 'He', 'is'),\n",
       " ('</s>', '<s>', 'Los'),\n",
       " ('<s>', 'They', 'are'),\n",
       " ('</s>', '<s>', 'However'),\n",
       " ('<s>', 'It', 'was'),\n",
       " ('</s>', '<s>', 'Then'),\n",
       " ('</s>', '<s>', 'One'),\n",
       " ('</s>', '<s>', 'At'),\n",
       " ('</s>', '<s>', 'These'),\n",
       " ('</s>', '<s>', 'On'),\n",
       " ('</s>', '<s>', 'So'),\n",
       " ('</s>', '<s>', 'La'),\n",
       " ('one', 'of', 'the'),\n",
       " ('a', 'lot', 'of'),\n",
       " ('</s>', '<s>', 'His'),\n",
       " ('</s>', '<s>', 'Scientists'),\n",
       " ('</s>', '<s>', 'No'),\n",
       " ('people', '</s>', '<s>'),\n",
       " ('<s>', 'There', 'are'),\n",
       " ('<s>', 'But', 'the'),\n",
       " ('</s>', '<s>', 'As'),\n",
       " ('</s>', '<s>', 'More'),\n",
       " ('</s>', '<s>', 'Most'),\n",
       " ('<s>', 'In', 'the'),\n",
       " ('</s>', '<s>', 'After'),\n",
       " ('<s>', 'This', 'is'),\n",
       " ('ago', '</s>', '<s>'),\n",
       " ('<s>', 'They', 'also'),\n",
       " ('time', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'En'),\n",
       " ('<s>', 'He', 'was'),\n",
       " ('in', 'the', 'United'),\n",
       " ('</s>', '<s>', 'Still'),\n",
       " ('</s>', '<s>', \"That's\"),\n",
       " ('<s>', 'They', 'were'),\n",
       " ('country', '</s>', '<s>'),\n",
       " ('money', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'Their'),\n",
       " ('school', '</s>', '<s>'),\n",
       " ('be', 'able', 'to'),\n",
       " ('years', 'ago', '</s>'),\n",
       " ('<s>', 'She', 'said'),\n",
       " ('</s>', '<s>', 'You'),\n",
       " ('States', '</s>', '<s>'),\n",
       " ('United', 'States', '</s>'),\n",
       " ('world', '</s>', '<s>'),\n",
       " ('government', '</s>', '<s>'),\n",
       " ('part', 'of', 'the'),\n",
       " ('work', '</s>', '<s>'),\n",
       " ('says', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'To'),\n",
       " ('</s>', '<s>', 'Even'),\n",
       " ('</s>', '<s>', 'Las'),\n",
       " ('</s>', '<s>', 'Pero'),\n",
       " ('water', '</s>', '<s>'),\n",
       " ('</s>', '<s>', 'All'),\n",
       " ('<s>', 'It', 'has'),\n",
       " ('the', 'University', 'of'),\n",
       " ('</s>', '<s>', 'Last'),\n",
       " ('<s>', 'She', 'is'),\n",
       " ('is', 'one', 'of'),\n",
       " ('</s>', '<s>', 'Her'),\n",
       " ('</s>', '<s>', 'Those')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcf.nbest(trigram_measures.raw_freq, 100)\n",
    "# [('</s>', '<s>', 'It'),\n",
    "#  ('<s>', 'It', 'is'),\n",
    "#  ('</s>', '<s>', 'I'),\n",
    "#  ('<s>', 'It', 'runs'),\n",
    "#  ('house', '</s>', '<s>'),\n",
    "#  ('</s>', '<s>', 'At'),\n",
    "#  ('It', 'is', 'very'),\n",
    "#  ('It', 'runs', 'after'),\n",
    "#  ('it', '</s>', '<s>'),\n",
    "#  ('the', 'house', '</s>')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You would usually want to filter some of them, e.g. the less frequent, although your dataset is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('U', '.', 'S'),\n",
       " ('.', 'S', '.'),\n",
       " ('he', 'said', '</s>'),\n",
       " ('<s>', 'It', 'is'),\n",
       " ('the', 'United', 'States'),\n",
       " ('the', 'U', '.'),\n",
       " ('<s>', 'He', 'said'),\n",
       " ('she', 'said', '</s>'),\n",
       " ('<s>', 'He', 'is'),\n",
       " ('<s>', 'They', 'are'),\n",
       " ('<s>', 'It', 'was'),\n",
       " ('one', 'of', 'the'),\n",
       " ('a', 'lot', 'of'),\n",
       " ('<s>', 'There', 'are'),\n",
       " ('<s>', 'But', 'the')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcf.apply_freq_filter(50)\n",
    "tcf.apply_ngram_filter(lambda w1, w2, w3: (\"<s>\" in [w1, w2, w3]) and (\"</s>\" in [w1, w2, w3]))\n",
    "\n",
    "tcf.nbest(trigram_measures.raw_freq, 15)\n",
    "\n",
    "# [('<s>', 'It', 'is'),\n",
    "#  ('<s>', 'It', 'runs'),\n",
    "#  ('It', 'is', 'very'),\n",
    "#  ('It', 'runs', 'after'),\n",
    "#  ('the', 'house', '</s>'),\n",
    "#  ('<s>', 'I', 'have'),\n",
    "#  ('<s>', 'It', 'has'),\n",
    "#  ('It', 'has', 'a'),\n",
    "#  ('member', 'of', 'the'),\n",
    "#  ('of', 'the', 'house')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally you apply the Kneser Ney smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9548424289008455: ('U', '.', 'S')\n",
      "0.9358190709046454: ('.', 'S', '.')\n",
      "0.9993472584856397: ('he', 'said', '</s>')\n",
      "0.34489845261121854: ('<s>', 'It', 'is')\n",
      "0.998877245508982: ('the', 'United', 'States')\n",
      "0.9987980769230769: ('the', 'U', '.')\n",
      "0.3327455236028215: ('<s>', 'He', 'said')\n",
      "0.9984567901234568: ('she', 'said', '</s>')\n",
      "0.25461204557786216: ('<s>', 'He', 'is')\n",
      "0.2547918948521358: ('<s>', 'They', 'are')\n",
      "0.2206237911025145: ('<s>', 'It', 'was')\n",
      "0.9980053191489362: ('one', 'of', 'the')\n",
      "0.9979564032697548: ('a', 'lot', 'of')\n",
      "0.4820336391437309: ('<s>', 'There', 'are')\n",
      "0.398005148005148: ('<s>', 'But', 'the')\n",
      "0.6764367816091954: ('<s>', 'In', 'the')\n",
      "0.7842465753424658: ('<s>', 'This', 'is')\n",
      "0.14964403066812706: ('<s>', 'They', 'also')\n",
      "0.14283776451437874: ('<s>', 'He', 'was')\n",
      "0.30962219598583235: ('in', 'the', 'United')\n",
      "0.13923877327491785: ('<s>', 'They', 'were')\n",
      "0.996875: ('be', 'able', 'to')\n",
      "0.9967672413793104: ('years', 'ago', '</s>')\n",
      "0.3086461126005362: ('<s>', 'She', 'said')\n",
      "0.7621107266435986: ('United', 'States', '</s>')\n",
      "0.7387931034482759: ('part', 'of', 'the')\n",
      "0.09489845261121857: ('<s>', 'It', 'has')\n",
      "0.9961928934010152: ('the', 'University', 'of')\n",
      "0.2603887399463807: ('<s>', 'She', 'is')\n",
      "0.9961340206185567: ('is', 'one', 'of')\n"
     ]
    }
   ],
   "source": [
    "kneser_ney = nltk.KneserNeyProbDist(tcf.ngram_fd)\n",
    "for i in tcf.nbest(trigram_measures.raw_freq, 30):\n",
    "    print(\"{0}: {1}\".format(kneser_ney.prob(i), i))\n",
    "\n",
    "# 0.31896551724137934: ('<s>', 'It', 'is')\n",
    "# 0.11206896551724138: ('<s>', 'It', 'runs')\n",
    "# 0.225: ('It', 'is', 'very')\n",
    "# 0.5625: ('It', 'runs', 'after')\n",
    "# 0.5625: ('the', 'house', '</s>')\n",
    "# 0.1388888888888889: ('<s>', 'I', 'have')\n",
    "# 0.04310344827586207: ('<s>', 'It', 'has')\n",
    "# 0.625: ('It', 'has', 'a')\n",
    "# 0.625: ('member', 'of', 'the')\n",
    "# 0.3125: ('of', 'the', 'house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961340206185567"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kneser_ney.prob(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from nltk.lm import MLE\n",
    ">>> lm = MLE(2)\n",
    ">>> lm.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
    ">>> lm.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
    ">>> lm.generate(random_seed=3)\n",
    "'a'\n",
    ">>> lm.generate(text_seed=['a'])\n",
    "'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import KneserNeyInterpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = KneserNeyInterpolated(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kn.fit([tcf.nbest(trigram_measures.raw_freq, 15)], vocabulary_text=list(library.grade_level_vocabulary(12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(library.grade_level_ngrams(5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(library.grade_level_ngrams(5, 3))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Ngram <<s>> isn't a tuple, but <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cd9b4681a99c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade_level_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade_level_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, text, vocabulary_text)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 )\n\u001b[1;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/counter.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, ngram_text)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     raise TypeError(\n\u001b[1;32m    124\u001b[0m                         \u001b[0;34m\"Ngram <{0}> isn't a tuple, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                         \u001b[0;34m\"but {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                     )\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Ngram <<s>> isn't a tuple, but <class 'str'>"
     ]
    }
   ],
   "source": [
    "kn.fit(library.grade_level_ngrams(5, 3), vocabulary_text=list(library.grade_level_vocabulary(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library.all_articles.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.perplexity(library.all_articles['10dollarbill-woman'].article_text(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([12, 8, 6, 5, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library.all_articles['10dollarbill-woman'].grade_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([12, 8, 6, 4, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library.all_articles['camden-hackathon'].grade_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-ee0f52ed21e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_articles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'10dollarbill-woman'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marticle_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mperplexity\u001b[0;34m(self, text_ngrams)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \"\"\"\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_ngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mentropy\u001b[0;34m(self, text_ngrams)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \"\"\"\n\u001b[1;32m    189\u001b[0m         return -1 * _mean(\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_ngrams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \"\"\"\n\u001b[1;32m    189\u001b[0m         return -1 * _mean(\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_ngrams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mlogscore\u001b[0;34m(self, word, context)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_base2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcontext_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, word, context)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \"\"\"\n\u001b[1;32m    142\u001b[0m         return self.unmasked_score(\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         )\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/models.py\u001b[0m in \u001b[0;36munmasked_score\u001b[0;34m(self, word, context)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munmasked_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munigram_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_gamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmasked_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/smoothing.py\u001b[0m in \u001b[0;36munigram_score\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munigram_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0malpha_gamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/vocabulary.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;34m\"\"\"Computing size of vocabulary reflects the cutoff.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/vocabulary.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;34m\"\"\"Computing size of vocabulary reflects the cutoff.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/vocabulary.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    222\u001b[0m         vocabulary.\"\"\"\n\u001b[1;32m    223\u001b[0m         return chain(\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         )\n",
      "\u001b[0;32m/anaconda3/envs/cs229/lib/python3.6/site-packages/nltk/lm/vocabulary.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cutoff\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_label\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \"\"\"Only consider items with counts GE to cutoff as being in the\n\u001b[1;32m    217\u001b[0m         vocabulary.\"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kn.perplexity(library.all_articles['10dollarbill-woman'].article_text(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.perplexity(library.all_articles['camden-hackathon'].article_text(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.fit([[(\"a\", \"b\"), (\"b\", \"c\")]], vocabulary_text=['a', 'b', 'c'])\n",
    "kn.fit([[(\"a\",), (\"b\",), (\"c\",)]])\n",
    "kn.generate(random_seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.generate(text_seed=['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn.perplexity(text_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(text, vocabulary_text=None)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.lm.KneserNeyInterpolated(order, discount=0.1, **kwargs)[source]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
